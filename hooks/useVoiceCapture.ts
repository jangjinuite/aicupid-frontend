"use client";

import { useState, useCallback, useRef, useEffect } from "react";
import { MicVAD } from "@ricky0123/vad-web";
import { useAudioQueue } from "@/hooks/useAudioQueue";
import { useAppContext } from "@/context/AppContext";
import type { AvatarState, GameEvent } from "@/types";

const BACKEND_URL =
  process.env.NEXT_PUBLIC_BACKEND_URL ?? "http://localhost:8000";

export type VoiceStatus = "idle" | "listening" | "speaking" | "ai_speaking" | "waiting";

export interface DebugEvent {
  ts: string;
  label: string;
  color: "green" | "yellow" | "blue" | "red" | "purple";
}

export interface UseVoiceCaptureReturn {
  status: VoiceStatus;
  isWaiting: boolean;
  avatarState: AvatarState;
  loading: boolean;
  error: string | null;
  gameEvent: GameEvent | null;
  debugLog: DebugEvent[];
  start: () => void;
  stop: () => void;
  forceCommit: () => void;
  dismissEvent: () => void;
  registerSpeechHandler: (handler: (blob: Blob) => void) => void;
  unregisterSpeechHandler: () => void;
  triggerPsychTest: () => Promise<void>;
  submitPsychTestResult: (blob1: Blob, blob2: Blob) => Promise<any>;
  triggerQuiz: () => Promise<void>;
  submitQuizResult: (blob: Blob, questionId: string) => Promise<any>;
  triggerBalanceGame: () => Promise<void>;
  submitBalanceGameResult: (blobs: [Blob, Blob, Blob], questionTexts: [string, string, string]) => Promise<any>;
}

// â”€â”€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function nowStr(): string {
  const d = new Date();
  return `${String(d.getHours()).padStart(2, "0")}:${String(d.getMinutes()).padStart(2, "0")}:${String(d.getSeconds()).padStart(2, "0")}.${String(d.getMilliseconds()).padStart(3, "0")}`;
}

/** Float32 PCM â†’ WAV Blob ë³€í™˜ */
function encodeWAV(samples: Float32Array, sampleRate: number = 16000): Blob {
  const buffer = new ArrayBuffer(44 + samples.length * 2);
  const view = new DataView(buffer);

  const writeString = (view: DataView, offset: number, string: string) => {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i));
    }
  };

  writeString(view, 0, 'RIFF');
  view.setUint32(4, 36 + samples.length * 2, true);
  writeString(view, 8, 'WAVE');
  writeString(view, 12, 'fmt ');
  view.setUint32(16, 16, true);
  view.setUint16(20, 1, true); // PCM
  view.setUint16(22, 1, true); // mono
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, sampleRate * 2, true);
  view.setUint16(32, 2, true);
  view.setUint16(34, 16, true);
  writeString(view, 36, 'data');
  view.setUint32(40, samples.length * 2, true);

  // Write PCM samples
  let offset = 44;
  for (let i = 0; i < samples.length; i++, offset += 2) {
    let s = Math.max(-1, Math.min(1, samples[i]));
    view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
  }

  return new Blob([buffer], { type: 'audio/wav' });
}

const MAX_LOG = 40;

// â”€â”€ Hook â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export function useVoiceCapture(): UseVoiceCaptureReturn {
  const { state: appState } = useAppContext();
  const [status, setStatus] = useState<VoiceStatus>("idle");
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);
  const [gameEvent, setGameEvent] = useState<GameEvent | null>(null);
  const [debugLog, setDebugLog] = useState<DebugEvent[]>([]);

  // refs
  const vadRef = useRef<MicVAD | null>(null);
  const destroyedRef = useRef(false);
  const isFetchingRef = useRef(false);
  const activeSessionIdRef = useRef<string | null>(null);
  const customSpeechHandlerRef = useRef<((blob: Blob) => void) | null>(null);

  // MediaRecorder refs (for partial audio capture on forceCommit)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const audioStreamRef = useRef<MediaStream | null>(null);

  const { playResponse, close: closeAudio } = useAudioQueue();

  const isWaiting = status === "waiting" || isFetchingRef.current;

  const avatarState: AvatarState = (() => {
    switch (status) {
      case "listening": return "listening";
      case "speaking": return "listening";
      case "ai_speaking": return "speaking";
      case "waiting": return "thinking";
      default: return "idle";
    }
  })();

  // â”€â”€ ë””ë²„ê·¸ ë¡œê·¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const pushLog = useCallback((label: string, color: DebugEvent["color"]) => {
    const entry: DebugEvent = { ts: nowStr(), label, color };
    console.log(`[Debug] ${entry.ts} ${label}`);
    setDebugLog((prev) => [entry, ...prev].slice(0, MAX_LOG));
  }, []);

  // â”€â”€ HTTP POST í†µì‹  (ìƒíƒœ ìœ ì§€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const sendAudioData = async (audioBlob: Blob) => {
    if (isFetchingRef.current) return;
    isFetchingRef.current = true;
    setStatus("waiting");
    pushLog(`â–¶ ì„œë²„ ì „ì†¡ ì¤‘... (${Math.round(audioBlob.size / 1024)}KB)`, "blue");

    try {
      const formData = new FormData();
      // íŒŒì¼ í™•ì¥ìë¥¼ Blobì˜ mime typeì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì„¤ì •
      const fileName = audioBlob.type.includes("webm") ? "audio.webm" : "audio.wav";
      formData.append("file", audioBlob, fileName);

      let endpoint = "";
      if (activeSessionIdRef.current) {
        endpoint = `${BACKEND_URL}/api/continue-conversation`;
        formData.append("session_id", activeSessionIdRef.current);
      } else {
        endpoint = `${BACKEND_URL}/api/first-conversation`;
        formData.append("user_id_1", appState.userProfile?.userId || "0");
        formData.append("user_id_2", appState.matchedUser?.userId || "0");
      }

      const res = await fetch(endpoint, {
        method: "POST",
        body: formData,
      });

      if (!res.ok) {
        throw new Error(`ì„œë²„ ì—ëŸ¬ (${res.status})`);
      }

      const data = await res.json();

      const newSessionId = data.session_id;
      if (newSessionId && !activeSessionIdRef.current) {
        activeSessionIdRef.current = newSessionId;
        pushLog(`âœ“ ì„¸ì…˜ ë°œê¸‰ë¨: ${newSessionId}`, "green");
      }

      const reply = data.reply;
      const audioB64 = data.audio;
      const mimeType = data.mime_type || "audio/wav";

      if (reply) {
        pushLog(`â—€ AI ë‹µë³€: ${reply}`, "green");
      }

      if (audioB64) {
        pushLog(`â—€ ì˜¤ë””ì˜¤ ìˆ˜ì‹  (${Math.round((audioB64.length * 3) / 4 / 1024)}KB)`, "blue");
        setStatus("ai_speaking");

        await playResponse(audioB64, mimeType, () => {
          pushLog("âœ“ ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ", "green");
          isFetchingRef.current = false;
          setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
        });
      } else {
        isFetchingRef.current = false;
        setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
      }

    } catch (err) {
      const msg = err instanceof Error ? err.message : String(err);
      pushLog(`âœ— í†µì‹  ì˜¤ë¥˜: ${msg}`, "red");
      setError(msg);
      isFetchingRef.current = false;
      setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
    }
  };

  const registerSpeechHandler = useCallback((handler: (blob: Blob) => void) => {
    customSpeechHandlerRef.current = handler;
  }, []);

  const unregisterSpeechHandler = useCallback(() => {
    customSpeechHandlerRef.current = null;
  }, []);

  const triggerPsychTest = useCallback(async () => {
    if (isFetchingRef.current) return;
    if (!activeSessionIdRef.current) {
      pushLog("âœ— ì§„í–‰ ì¤‘ì¸ ì„¸ì…˜ì´ ì—†ì–´ ì‹¬ë¦¬í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ì–´ìš”", "red");
      return;
    }

    isFetchingRef.current = true;
    setStatus("waiting");
    pushLog("â–¶ ì‹¬ë¦¬í…ŒìŠ¤íŠ¸ ë¬¸ì œ ìš”ì²­ ì¤‘...", "blue");

    try {
      const formData = new FormData();
      const sampleRate = 16000;
      const silentFloat32 = new Float32Array(sampleRate * 0.5);
      const wavBlob = encodeWAV(silentFloat32, sampleRate);
      formData.append("file", wavBlob, "audio.wav");
      formData.append("session_id", activeSessionIdRef.current);

      const res = await fetch(`${BACKEND_URL}/api/psych-test`, {
        method: "POST",
        body: formData,
      });

      if (!res.ok) throw new Error(`ì„œë²„ ì—ëŸ¬ (${res.status})`);
      const data = await res.json();

      const reply = data.reply || data.response || "ì‹¬ë¦¬í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ì…ë‹ˆë‹¤.";
      const audioB64 = data.audio;
      const mimeType = data.mime_type || "audio/wav";

      setGameEvent({ type: "psych", question: reply, choices: [] });

      if (audioB64) {
        pushLog(`â—€ ì˜¤ë””ì˜¤ ìˆ˜ì‹  (${Math.round((audioB64.length * 3) / 4 / 1024)}KB)`, "blue");
        setStatus("ai_speaking");

        await playResponse(audioB64, mimeType, () => {
          isFetchingRef.current = false;
          setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
        });
      } else {
        isFetchingRef.current = false;
        setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
      }
    } catch (err) {
      pushLog(`âœ— ì‹¬ë¦¬í…ŒìŠ¤íŠ¸ í˜¸ì¶œ ì˜¤ë¥˜: ${err}`, "red");
      isFetchingRef.current = false;
      setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
    }
  }, [playResponse, pushLog]);

  const submitPsychTestResult = useCallback(async (blob1: Blob, blob2: Blob) => {
    if (!activeSessionIdRef.current) throw new Error("No active session");

    isFetchingRef.current = true;
    setStatus("waiting");
    pushLog(`â–¶ ì‹¬ë¦¬í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„ ì¤‘...`, "blue");

    try {
      const formData = new FormData();
      formData.append("session_id", activeSessionIdRef.current);
      const ext1 = blob1.type.includes("webm") ? "webm" : "wav";
      const ext2 = blob2.type.includes("webm") ? "webm" : "wav";
      formData.append("file_1", blob1, `audio1.${ext1}`);
      formData.append("file_2", blob2, `audio2.${ext2}`);

      const res = await fetch(`${BACKEND_URL}/api/psych-test-result`, {
        method: "POST",
        body: formData,
      });

      if (!res.ok) throw new Error(`ì„œë²„ ì—ëŸ¬ (${res.status})`);
      const data = await res.json();

      if (data.audio) {
        setStatus("ai_speaking");

        await playResponse(data.audio, data.mime_type || "audio/wav", () => {
          isFetchingRef.current = false;
          setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
        });
      } else {
        isFetchingRef.current = false;
        setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
      }

      return data;
    } catch (err) {
      pushLog(`âœ— ê²°ê³¼ ë¶„ì„ ì˜¤ë¥˜: ${err}`, "red");
      isFetchingRef.current = false;
      setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
      throw err;
    }
  }, [playResponse, pushLog]);

  // â”€â”€ í€´ì¦ˆ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const triggerQuiz = useCallback(async () => {
    if (isFetchingRef.current) return;
    if (!activeSessionIdRef.current) {
      pushLog("âœ— ì§„í–‰ ì¤‘ì¸ ì„¸ì…˜ì´ ì—†ì–´ í€´ì¦ˆë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ì–´ìš”", "red");
      return;
    }

    isFetchingRef.current = true;
    setStatus("waiting");
    pushLog("â–¶ í€´ì¦ˆ ë¬¸ì œ ìš”ì²­ ì¤‘...", "blue");

    try {
      const body = new URLSearchParams();
      body.append("session_id", activeSessionIdRef.current);

      const res = await fetch(`${BACKEND_URL}/api/four-choice-quiz`, {
        method: "POST",
        headers: {
          "Content-Type": "application/x-www-form-urlencoded",
        },
        body: body.toString(),
      });

      if (!res.ok) throw new Error(`ì„œë²„ ì—ëŸ¬ (${res.status})`);
      const data = await res.json();

      // data = { question_id, text, options(array), audio, mime_type }
      setGameEvent({
        type: "quiz",
        questionId: data.question_id,
        question: data.text,
        choices: data.options || ["A", "B", "C", "D"]
      });

      if (data.audio) {
        pushLog(`â—€ í€´ì¦ˆ ë¬¸ì œ ì˜¤ë””ì˜¤ ìˆ˜ì‹ `, "blue");
        setStatus("ai_speaking");

        await playResponse(data.audio, data.mime_type || "audio/wav", () => {
          isFetchingRef.current = false;
          setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
        });
      } else {
        isFetchingRef.current = false;
        setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
      }

    } catch (err) {
      pushLog(`âœ— í€´ì¦ˆ í˜¸ì¶œ ì˜¤ë¥˜: ${err}`, "red");
      isFetchingRef.current = false;
      setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
    }
  }, [playResponse, pushLog]);

  const submitQuizResult = useCallback(async (blob: Blob, questionId: string) => {
    if (!activeSessionIdRef.current) throw new Error("No active session");

    isFetchingRef.current = true;
    setStatus("waiting");
    pushLog(`â–¶ í€´ì¦ˆ ì •ë‹µ í™•ì¸ ì¤‘...`, "blue");

    try {
      const formData = new FormData();
      const ext = blob.type.includes("webm") ? "webm" : "wav";
      formData.append("file", blob, `answer.${ext}`);
      formData.append("question_id", questionId);
      formData.append("session_id", activeSessionIdRef.current);

      const res = await fetch(`${BACKEND_URL}/api/quiz-result`, {
        method: "POST",
        body: formData,
      });

      if (!res.ok) throw new Error(`ì„œë²„ ì—ëŸ¬ (${res.status})`);
      const data = await res.json();

      if (data.audio) {
        setStatus("ai_speaking");
        await playResponse(data.audio, data.mime_type || "audio/wav", () => {
          isFetchingRef.current = false;
          setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
        });
      } else {
        isFetchingRef.current = false;
        setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
      }

      return data;
    } catch (err) {
      pushLog(`âœ— í€´ì¦ˆ ê²°ê³¼ ë¶„ì„ ì˜¤ë¥˜: ${err}`, "red");
      isFetchingRef.current = false;
      setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
      throw err;
    }
  }, [playResponse, pushLog]);

  // â”€â”€ ë°¸ëŸ°ìŠ¤ ê²Œì„ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const triggerBalanceGame = useCallback(async () => {
    if (isFetchingRef.current) return;
    if (!activeSessionIdRef.current) {
      pushLog("âœ— ì§„í–‰ ì¤‘ì¸ ì„¸ì…˜ì´ ì—†ì–´ ë°¸ëŸ°ìŠ¤ ê²Œì„ì„ ì‹œì‘í•  ìˆ˜ ì—†ì–´ìš”", "red");
      return;
    }

    isFetchingRef.current = true;
    setStatus("waiting");
    pushLog("â–¶ ë°¸ëŸ°ìŠ¤ ê²Œì„ ë¬¸ì œ ìš”ì²­ ì¤‘...", "blue");

    try {
      const formData = new FormData();
      formData.append("session_id", activeSessionIdRef.current);

      const res = await fetch(`${BACKEND_URL}/api/balance-game-questions`, {
        method: "POST",
        body: formData,
      });

      if (!res.ok) throw new Error(`ì„œë²„ ì—ëŸ¬ (${res.status})`);
      const data = await res.json();

      // Expected: { questions: [{ text, options: [A, B], audio, mime_type }, x3] }
      const questions = data.questions as { text: string; options: string[]; audio?: string; mime_type?: string }[];

      setGameEvent({
        type: "balance",
        question: questions[0].text,
        choices: questions[0].options,
        questions,
      });

      if (questions[0].audio) {
        pushLog(`â—€ ë°¸ëŸ°ìŠ¤ ê²Œì„ ì²« ë²ˆì§¸ ë¬¸ì œ ì˜¤ë””ì˜¤ ìˆ˜ì‹ `, "blue");
        setStatus("ai_speaking");
        await playResponse(questions[0].audio, questions[0].mime_type || "audio/wav", () => {
          isFetchingRef.current = false;
          setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
        });
      } else {
        isFetchingRef.current = false;
        setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
      }
    } catch (err) {
      pushLog(`âœ— ë°¸ëŸ°ìŠ¤ ê²Œì„ í˜¸ì¶œ ì˜¤ë¥˜: ${err}`, "red");
      isFetchingRef.current = false;
      setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
    }
  }, [playResponse, pushLog]);

  const submitBalanceGameResult = useCallback(async (blobs: [Blob, Blob, Blob], questionTexts: [string, string, string]) => {
    if (!activeSessionIdRef.current) throw new Error("No active session");

    isFetchingRef.current = true;
    setStatus("waiting");
    pushLog(`â–¶ ë°¸ëŸ°ìŠ¤ ê²Œì„ ê²°ê³¼ ë¶„ì„ ì¤‘...`, "blue");

    try {
      const formData = new FormData();
      formData.append("session_id", activeSessionIdRef.current);
      formData.append("question_text_1", questionTexts[0]);
      formData.append("question_text_2", questionTexts[1]);
      formData.append("question_text_3", questionTexts[2]);
      const ext = (b: Blob) => b.type.includes("webm") ? "webm" : "wav";
      formData.append("file_1", blobs[0], `answer1.${ext(blobs[0])}`);
      formData.append("file_2", blobs[1], `answer2.${ext(blobs[1])}`);
      formData.append("file_3", blobs[2], `answer3.${ext(blobs[2])}`);

      const res = await fetch(`${BACKEND_URL}/api/balance-game-result`, {
        method: "POST",
        body: formData,
      });

      if (!res.ok) throw new Error(`ì„œë²„ ì—ëŸ¬ (${res.status})`);
      const data = await res.json();

      if (data.audio) {
        setStatus("ai_speaking");
        await playResponse(data.audio, data.mime_type || "audio/wav", () => {
          isFetchingRef.current = false;
          setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
        });
      } else {
        isFetchingRef.current = false;
        setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
      }

      return data;
    } catch (err) {
      pushLog(`âœ— ë°¸ëŸ°ìŠ¤ ê²Œì„ ê²°ê³¼ ë¶„ì„ ì˜¤ë¥˜: ${err}`, "red");
      isFetchingRef.current = false;
      setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
      throw err;
    }
  }, [playResponse, pushLog]);

  // â”€â”€ MediaRecorder ì œì–´ ë¡œì§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const startMediaRecorder = async () => {
    try {
      if (!audioStreamRef.current) {
        audioStreamRef.current = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
          }
        });
      }
      const stream = audioStreamRef.current;
      audioChunksRef.current = [];

      const mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
      mediaRecorderRef.current = mediaRecorder;

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.start(100); // Record in 100ms chunks to ensure data availability on quick stops
      pushLog("â—‹ ì˜¤ë””ì˜¤ ë ˆì½”ë”© ì‹œì‘", "green");
    } catch (err) {
      pushLog("âœ— ë§ˆì´í¬ ê¶Œí•œì´ ì œí•œë¨", "red");
    }
  };

  const stopAndProcessMediaRecorder = (): Promise<Blob | null> => {
    return new Promise((resolve) => {
      const mediaRecorder = mediaRecorderRef.current;
      if (!mediaRecorder || mediaRecorder.state === "inactive") {
        resolve(null);
        return;
      }

      const handleStop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        audioChunksRef.current = [];
        resolve(audioBlob);
      };

      mediaRecorder.onstop = handleStop;
      mediaRecorder.stop();
    });
  };

  // â”€â”€ MicVAD ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  useEffect(() => {
    destroyedRef.current = false;

    MicVAD.new({
      startOnLoad: false,
      baseAssetPath: "/",
      onnxWASMBasePath: "/",
      positiveSpeechThreshold: 0.90, // ì¢€ ë” í™•ì‹¤í•œ ìŒì„±ë§Œ ê°ì§€í•˜ë„ë¡ ìƒí–¥ (ê¸°ë³¸ê°’ë³´ë‹¤ ë†’ìŒ)
      negativeSpeechThreshold: 0.75, // ë¹¨ë¦¬ ëŠê¸°ë„ë¡ í•˜í–¥ ì¡°ì •

      onSpeechStart() {
        if (isFetchingRef.current) return;
        pushLog("ğŸ™ ì‚¬ìš©ìê°€ ë§í•˜ê¸° ì‹œì‘í•¨", "yellow");
        setStatus((prev) => (prev === "listening" ? "speaking" : prev));
      },

      async onSpeechEnd(audio: Float32Array) {
        if (isFetchingRef.current) return;
        pushLog("ğŸ”‡ ì‚¬ìš©ìê°€ ë§í•˜ê¸° ëë‚¨", "yellow");
        setStatus("waiting");

        // VADê°€ ëë‚¬ìœ¼ë¯€ë¡œ ì§„í–‰ ì¤‘ì´ë˜ MediaRecorder ë…¹ìŒë³¸ì„ ë½‘ì•„ëƒ„
        const recordedWebm = await stopAndProcessMediaRecorder();

        // VADê°€ ì œê³µí•˜ëŠ” ë°±ì—…ìš© Float32Array(16kHz)ë¥¼ WAV Blobìœ¼ë¡œ ë³€í™˜ (ë³´ì¡°ìš©)
        const vadWavBlob = encodeWAV(audio, 16000);

        // ë¸Œë¼ìš°ì € í¬ë§·(WebM)ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ VADì˜ 16kHz WAV ì‚¬ìš©
        const finalBlob = recordedWebm && recordedWebm.size > 0 ? recordedWebm : vadWavBlob;

        if (customSpeechHandlerRef.current) {
          customSpeechHandlerRef.current(finalBlob);
          // í•¸ë“¤ëŸ¬ê°€ ì„œë²„ ìš”ì²­ì„ ì‹œì‘í•˜ì§€ ì•Šì•˜ìœ¼ë©´(isFetchingRef ì—¬ì „íˆ false) ë°”ë¡œ listening ë³µê·€
          if (!isFetchingRef.current) {
            setStatus("listening");
          }
        } else {
          void sendAudioData(finalBlob);
        }
      },

      onVADMisfire() {
        if (isFetchingRef.current) return;
        pushLog("âš¡ ì˜ë¯¸ ì—†ëŠ” ì†ŒìŒ(VAD misfire)", "red");
        setStatus((prev) => (prev === "speaking" ? "listening" : prev));
        // Misfireë©´ ë ˆì½”ë” ì´ˆê¸°í™”
        void stopAndProcessMediaRecorder().then(() => startMediaRecorder());
      },
    })
      .then((myvad) => {
        if (destroyedRef.current) { void myvad.destroy(); return; }
        vadRef.current = myvad;
        setLoading(false);
        pushLog("âœ“ VAD ì´ˆê¸°í™” ì™„ë£Œ", "green");
      })
      .catch((err: unknown) => {
        const msg = err instanceof Error ? err.message : String(err);
        pushLog(`âœ— VAD ì´ˆê¸°í™” ì‹¤íŒ¨: ${msg}`, "red");
        setError(msg);
        setLoading(false);
      });

    return () => {
      destroyedRef.current = true;
      const vad = vadRef.current;
      if (vad) { vadRef.current = null; void vad.destroy(); }

      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
        mediaRecorderRef.current.stop();
      }
      if (audioStreamRef.current) {
        audioStreamRef.current.getTracks().forEach(track => track.stop());
      }

      closeAudio();
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  // â”€â”€ Force commit (ì•„ë°”íƒ€ íƒ­) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const forceCommit = useCallback(async () => {
    if (isFetchingRef.current) return;
    pushLog("ğŸ‘† ì•„ë°”íƒ€ ê°•ì œ íƒ­! ëˆ„ì  ì˜¤ë””ì˜¤ ì „ì†¡", "yellow");
    setStatus("waiting");

    // ì´ë•Œê¹Œì§€ ëª¨ì¸ MediaRecorder ë…¹ìŒë³¸ ì¶”ì¶œ
    let recordedBlob = await stopAndProcessMediaRecorder();

    // í˜¹ì‹œë¼ë„ (ë„ˆë¬´ ë¹¨ë¦¬ ëˆŒëŸ¬ì„œ) 0ë°”ì´íŠ¸ë©´ ì§§ì€ ë¹ˆ WAV ìƒì„±
    if (!recordedBlob || recordedBlob.size === 0) {
      const sampleRate = 16000;
      const durationSec = 0.5;
      const silentFloat32 = new Float32Array(sampleRate * durationSec);
      recordedBlob = encodeWAV(silentFloat32, sampleRate);
      pushLog("ë¹ˆ ì˜¤ë””ì˜¤(fallback) ìƒì„±ë¨", "yellow");
    }

    if (customSpeechHandlerRef.current) {
      customSpeechHandlerRef.current(recordedBlob);
      // í•¸ë“¤ëŸ¬ê°€ ì„œë²„ ìš”ì²­ì„ ì‹œì‘í•˜ì§€ ì•Šì•˜ìœ¼ë©´(isFetchingRef ì—¬ì „íˆ false) ë°”ë¡œ listening ë³µê·€
      if (!isFetchingRef.current) {
        setStatus("listening");
      }
    } else {
      await sendAudioData(recordedBlob);
    }

    // ì²˜ë¦¬ê°€ ëë‚˜ê³  idle/listening ìƒíƒœë¡œ ëŒì•„ê°ˆë•Œ VAD ì¬ê¸°ë™
    if (vadRef.current && !destroyedRef.current) {
      void vadRef.current.start();
      void startMediaRecorder(); // ë‹¤ìŒ ìŒì„± ìº¡ì²˜ìš©ìœ¼ë¡œ ë ˆì½”ë” ì¬ì‹œì‘
    }

  }, [sendAudioData, pushLog]);

  // â”€â”€ ì„¸ì…˜ ì‹œì‘ / ì¤‘ì§€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const start = useCallback(() => {
    const vad = vadRef.current;
    if (!vad) return;
    void vad.start();
    void startMediaRecorder();
    setStatus("listening");
    pushLog("â–¶ ì„¸ì…˜ ì‹œì‘", "green");
  }, [pushLog]);

  const stop = useCallback(() => {
    const vad = vadRef.current;
    if (vad) void vad.pause();

    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
      mediaRecorderRef.current.stop();
    }

    closeAudio();
    activeSessionIdRef.current = null;
    setStatus("idle");
    pushLog("â–  ì„¸ì…˜ ì¤‘ì§€ ë° ì´ˆê¸°í™”", "yellow");
  }, [closeAudio, pushLog]);

  const dismissEvent = useCallback(() => setGameEvent(null), []);

  return {
    status, isWaiting, avatarState,
    loading, error, gameEvent, debugLog,
    start, stop, forceCommit, dismissEvent,
    registerSpeechHandler, unregisterSpeechHandler,
    triggerPsychTest, submitPsychTestResult,
    triggerQuiz, submitQuizResult,
    triggerBalanceGame, submitBalanceGameResult,
  };
}
