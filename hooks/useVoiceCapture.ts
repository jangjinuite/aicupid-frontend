"use client";

import { useState, useCallback, useRef, useEffect } from "react";
import { MicVAD } from "@ricky0123/vad-web";
import { useAudioQueue } from "@/hooks/useAudioQueue";
import type { AvatarState, GameEvent } from "@/types";

const BACKEND_URL =
  process.env.NEXT_PUBLIC_BACKEND_URL ?? "http://localhost:8000";

export type VoiceStatus = "idle" | "listening" | "speaking" | "ai_speaking" | "waiting";

export interface DebugEvent {
  ts: string;
  label: string;
  color: "green" | "yellow" | "blue" | "red" | "purple";
}

export interface UseVoiceCaptureReturn {
  status: VoiceStatus;
  isWaiting: boolean;
  avatarState: AvatarState;
  loading: boolean;
  error: string | null;
  gameEvent: GameEvent | null;
  debugLog: DebugEvent[];
  start: () => void;
  stop: () => void;
  forceCommit: () => void;
  dismissEvent: () => void;
}

// â”€â”€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function nowStr(): string {
  const d = new Date();
  return `${String(d.getHours()).padStart(2, "0")}:${String(d.getMinutes()).padStart(2, "0")}:${String(d.getSeconds()).padStart(2, "0")}.${String(d.getMilliseconds()).padStart(3, "0")}`;
}

/** Float32 PCM â†’ WAV Blob ë³€í™˜ */
function encodeWAV(samples: Float32Array, sampleRate: number = 16000): Blob {
  const buffer = new ArrayBuffer(44 + samples.length * 2);
  const view = new DataView(buffer);

  const writeString = (view: DataView, offset: number, string: string) => {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i));
    }
  };

  writeString(view, 0, 'RIFF');
  view.setUint32(4, 36 + samples.length * 2, true);
  writeString(view, 8, 'WAVE');
  writeString(view, 12, 'fmt ');
  view.setUint32(16, 16, true);
  view.setUint16(20, 1, true); // PCM
  view.setUint16(22, 1, true); // mono
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, sampleRate * 2, true);
  view.setUint16(32, 2, true);
  view.setUint16(34, 16, true);
  writeString(view, 36, 'data');
  view.setUint32(40, samples.length * 2, true);

  // Write PCM samples
  let offset = 44;
  for (let i = 0; i < samples.length; i++, offset += 2) {
    let s = Math.max(-1, Math.min(1, samples[i]));
    view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
  }

  return new Blob([buffer], { type: 'audio/wav' });
}

const MAX_LOG = 40;

// â”€â”€ Hook â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export function useVoiceCapture(): UseVoiceCaptureReturn {
  const [status, setStatus] = useState<VoiceStatus>("idle");
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);
  const [gameEvent, setGameEvent] = useState<GameEvent | null>(null);
  const [debugLog, setDebugLog] = useState<DebugEvent[]>([]);

  // refs
  const vadRef = useRef<MicVAD | null>(null);
  const destroyedRef = useRef(false);
  const isFetchingRef = useRef(false);
  const activeSessionIdRef = useRef<string | null>(null);

  // MediaRecorder refs (for partial audio capture on forceCommit)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const audioStreamRef = useRef<MediaStream | null>(null);

  const { playResponse, close: closeAudio } = useAudioQueue();

  const isWaiting = status === "waiting" || isFetchingRef.current;

  const avatarState: AvatarState = (() => {
    switch (status) {
      case "listening": return "listening";
      case "speaking": return "listening";
      case "ai_speaking": return "speaking";
      case "waiting": return "thinking";
      default: return "idle";
    }
  })();

  // â”€â”€ ë””ë²„ê·¸ ë¡œê·¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const pushLog = useCallback((label: string, color: DebugEvent["color"]) => {
    const entry: DebugEvent = { ts: nowStr(), label, color };
    console.log(`[Debug] ${entry.ts} ${label}`);
    setDebugLog((prev) => [entry, ...prev].slice(0, MAX_LOG));
  }, []);

  // â”€â”€ HTTP POST í†µì‹  (ìƒíƒœ ìœ ì§€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const sendAudioData = async (audioBlob: Blob) => {
    if (isFetchingRef.current) return;
    isFetchingRef.current = true;
    setStatus("waiting");
    pushLog(`â–¶ ì„œë²„ ì „ì†¡ ì¤‘... (${Math.round(audioBlob.size / 1024)}KB)`, "blue");

    try {
      const formData = new FormData();
      // íŒŒì¼ í™•ì¥ìë¥¼ Blobì˜ mime typeì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì„¤ì •
      const fileName = audioBlob.type.includes("webm") ? "audio.webm" : "audio.wav";
      formData.append("file", audioBlob, fileName);

      let endpoint = "";
      if (activeSessionIdRef.current) {
        endpoint = `${BACKEND_URL}/api/continue-conversation`;
        formData.append("session_id", activeSessionIdRef.current);
      } else {
        endpoint = `${BACKEND_URL}/api/first-conversation`;
        formData.append("user_id_1", "0");
        formData.append("user_id_2", "0");
      }

      const res = await fetch(endpoint, {
        method: "POST",
        body: formData,
      });

      if (!res.ok) {
        throw new Error(`ì„œë²„ ì—ëŸ¬ (${res.status})`);
      }

      const data = await res.json();

      const newSessionId = data.session_id;
      if (newSessionId && !activeSessionIdRef.current) {
        activeSessionIdRef.current = newSessionId;
        pushLog(`âœ“ ì„¸ì…˜ ë°œê¸‰ë¨: ${newSessionId}`, "green");
      }

      const reply = data.reply;
      const audioB64 = data.audio;
      const mimeType = data.mime_type || "audio/wav";

      if (reply) {
        pushLog(`â—€ AI ë‹µë³€: ${reply}`, "green");
      }

      if (audioB64) {
        pushLog(`â—€ ì˜¤ë””ì˜¤ ìˆ˜ì‹  (${Math.round((audioB64.length * 3) / 4 / 1024)}KB)`, "blue");
        setStatus("ai_speaking");
        await playResponse(audioB64, mimeType);
        pushLog("âœ“ ì¬ìƒ ì™„ë£Œ", "blue");
      }

    } catch (err) {
      const msg = err instanceof Error ? err.message : String(err);
      pushLog(`âœ— í†µì‹  ì˜¤ë¥˜: ${msg}`, "red");
      setError(msg);
    } finally {
      isFetchingRef.current = false;
      setStatus((prev) => (prev === "ai_speaking" || prev === "waiting") ? "listening" : prev);
    }
  };

  // â”€â”€ MediaRecorder ì œì–´ ë¡œì§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const startMediaRecorder = async () => {
    try {
      if (!audioStreamRef.current) {
        audioStreamRef.current = await navigator.mediaDevices.getUserMedia({ audio: true });
      }
      const stream = audioStreamRef.current;
      audioChunksRef.current = [];

      const mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
      mediaRecorderRef.current = mediaRecorder;

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.start(100); // Record in 100ms chunks to ensure data availability on quick stops
      pushLog("â—‹ ì˜¤ë””ì˜¤ ë ˆì½”ë”© ì‹œì‘", "green");
    } catch (err) {
      pushLog("âœ— ë§ˆì´í¬ ê¶Œí•œì´ ì œí•œë¨", "red");
    }
  };

  const stopAndProcessMediaRecorder = (): Promise<Blob | null> => {
    return new Promise((resolve) => {
      const mediaRecorder = mediaRecorderRef.current;
      if (!mediaRecorder || mediaRecorder.state === "inactive") {
        resolve(null);
        return;
      }

      const handleStop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        audioChunksRef.current = [];
        resolve(audioBlob);
      };

      mediaRecorder.onstop = handleStop;
      mediaRecorder.stop();
    });
  };

  // â”€â”€ MicVAD ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  useEffect(() => {
    destroyedRef.current = false;

    MicVAD.new({
      startOnLoad: false,
      baseAssetPath: "/",
      onnxWASMBasePath: "/",

      onSpeechStart() {
        if (isFetchingRef.current) return;
        pushLog("ğŸ™ ì‚¬ìš©ìê°€ ë§í•˜ê¸° ì‹œì‘í•¨", "yellow");
        setStatus((prev) => (prev === "listening" ? "speaking" : prev));
      },

      async onSpeechEnd(audio: Float32Array) {
        if (isFetchingRef.current) return;
        pushLog("ğŸ”‡ ì‚¬ìš©ìê°€ ë§í•˜ê¸° ëë‚¨", "yellow");
        setStatus("waiting");

        // VADê°€ ëë‚¬ìœ¼ë¯€ë¡œ ì§„í–‰ ì¤‘ì´ë˜ MediaRecorder ë…¹ìŒë³¸ì„ ë½‘ì•„ëƒ„
        const recordedWebm = await stopAndProcessMediaRecorder();

        // VADê°€ ì œê³µí•˜ëŠ” ë°±ì—…ìš© Float32Array(16kHz)ë¥¼ WAV Blobìœ¼ë¡œ ë³€í™˜ (ë³´ì¡°ìš©)
        const vadWavBlob = encodeWAV(audio, 16000);

        // ë¸Œë¼ìš°ì € í¬ë§·(WebM)ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ VADì˜ 16kHz WAV ì‚¬ìš©
        const finalBlob = recordedWebm && recordedWebm.size > 0 ? recordedWebm : vadWavBlob;

        void sendAudioData(finalBlob);
      },

      onVADMisfire() {
        if (isFetchingRef.current) return;
        pushLog("âš¡ ì˜ë¯¸ ì—†ëŠ” ì†ŒìŒ(VAD misfire)", "red");
        setStatus((prev) => (prev === "speaking" ? "listening" : prev));
        // Misfireë©´ ë ˆì½”ë” ì´ˆê¸°í™”
        void stopAndProcessMediaRecorder().then(() => startMediaRecorder());
      },
    })
      .then((myvad) => {
        if (destroyedRef.current) { void myvad.destroy(); return; }
        vadRef.current = myvad;
        setLoading(false);
        pushLog("âœ“ VAD ì´ˆê¸°í™” ì™„ë£Œ", "green");
      })
      .catch((err: unknown) => {
        const msg = err instanceof Error ? err.message : String(err);
        pushLog(`âœ— VAD ì´ˆê¸°í™” ì‹¤íŒ¨: ${msg}`, "red");
        setError(msg);
        setLoading(false);
      });

    return () => {
      destroyedRef.current = true;
      const vad = vadRef.current;
      if (vad) { vadRef.current = null; void vad.destroy(); }

      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
        mediaRecorderRef.current.stop();
      }
      if (audioStreamRef.current) {
        audioStreamRef.current.getTracks().forEach(track => track.stop());
      }

      closeAudio();
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  // â”€â”€ Force commit (ì•„ë°”íƒ€ íƒ­) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const forceCommit = useCallback(async () => {
    if (isFetchingRef.current) return;
    pushLog("ğŸ‘† ì•„ë°”íƒ€ ê°•ì œ íƒ­! ëˆ„ì  ì˜¤ë””ì˜¤ ì „ì†¡", "yellow");
    setStatus("waiting");

    // VAD ê°•ì œ ì¼ì‹œ ì •ì§€ (ì§„í–‰ ì¤‘ì¸ VAD ë²„í¼ë§ ìº”ìŠ¬ìš©)
    const vad = vadRef.current;
    if (vad) void vad.pause();

    // ì´ë•Œê¹Œì§€ ëª¨ì¸ MediaRecorder ë…¹ìŒë³¸ ì¶”ì¶œ
    let recordedBlob = await stopAndProcessMediaRecorder();

    // í˜¹ì‹œë¼ë„ (ë„ˆë¬´ ë¹¨ë¦¬ ëˆŒëŸ¬ì„œ) 0ë°”ì´íŠ¸ë©´ ì§§ì€ ë¹ˆ WAV ìƒì„±
    if (!recordedBlob || recordedBlob.size === 0) {
      const sampleRate = 16000;
      const durationSec = 0.5;
      const silentFloat32 = new Float32Array(sampleRate * durationSec);
      recordedBlob = encodeWAV(silentFloat32, sampleRate);
      pushLog("ë¹ˆ ì˜¤ë””ì˜¤(fallback) ìƒì„±ë¨", "yellow");
    }

    await sendAudioData(recordedBlob);

    // ì²˜ë¦¬ê°€ ëë‚˜ê³  idle/listening ìƒíƒœë¡œ ëŒì•„ê°ˆë•Œ VAD ì¬ê¸°ë™
    if (vadRef.current && !destroyedRef.current) {
      void vadRef.current.start();
      void startMediaRecorder(); // ë‹¤ìŒ ìŒì„± ìº¡ì²˜ìš©ìœ¼ë¡œ ë ˆì½”ë” ì¬ì‹œì‘
    }

  }, [sendAudioData, pushLog]);

  // â”€â”€ ì„¸ì…˜ ì‹œì‘ / ì¤‘ì§€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const start = useCallback(() => {
    const vad = vadRef.current;
    if (!vad) return;
    void vad.start();
    void startMediaRecorder();
    setStatus("listening");
    pushLog("â–¶ ì„¸ì…˜ ì‹œì‘", "green");
  }, [pushLog]);

  const stop = useCallback(() => {
    const vad = vadRef.current;
    if (vad) void vad.pause();

    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
      mediaRecorderRef.current.stop();
    }

    closeAudio();
    activeSessionIdRef.current = null;
    setStatus("idle");
    pushLog("â–  ì„¸ì…˜ ì¤‘ì§€ ë° ì´ˆê¸°í™”", "yellow");
  }, [closeAudio, pushLog]);

  const dismissEvent = useCallback(() => setGameEvent(null), []);

  return {
    status, isWaiting, avatarState,
    loading, error, gameEvent, debugLog,
    start, stop, forceCommit, dismissEvent,
  };
}
